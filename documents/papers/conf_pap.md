---
title: "Conference Paper: Kalamazoo 2019"
author: J. Schoen & G. E. Saretto
date: May 2019
---

|Pages|Words|Paragraphs|
|:---|:---|:---|
|8|2000|8|

- In this talk I will tell you about an experiment with Optical Character Recognition--or OCR--which I attempted in collaboration with a fellow graduate student, Jenna Schoen. Jenna would have gladly co-presented these findings with me, and participated in this exciting panel with all of you. Unfortunately, she has been asked to deliver a paper on _Pearl_ at a session that is taking place right at this moment. So, you will have to content yourselves with the lesser half of the team for now. Nevertheless, both our contacts are listed here, and both of us would be quite happy to further discuss these ideas with you on some other occasion--either here at Kalamazoo or by email later.

- Now, we started this project about a year and a half ago, within Columbia's Group for Experimental Methods in Humanistic Research. We were also funded by Columbia's Data Science Institute to continue it over the summer of 2018. The experiment itself consisted in using a preexistent OCR software--called _Kraken_, like Tennyson's giant squid--to train a model for the automatic recognition and transcription of a Middle English book hand from the early 15th century. In the next few minutes, I will describe this process and these choices in more detail.

- However, before I do so, I would like to reflect on why we decided to attempt this experiment in the first place. Why should one try to use OCR for medieval manuscripts? What would one gain from teaching computers to transcribe 14th and 15th-century book hands? I mean, apart from upsetting paleographers. Well, the advantages might sound redundant to a room full of medievalists, but it does not hurt to recapitulate them. So, take for instance EEBO--the massive database of Early English Books Online that launched in 1998. Today, EEBO contains digital facsimiles of more than one hundred thousand printed books, adding up to millions of pages. So far, nothing particularly exciting; photographic reproductions of medieval manuscripts are also becoming increasingly accessible. This has happened thanks to numberless digitization projects funded by libraries and universities everywhere, and to several comprehensive databases that facilitate our searches--such as _Digital Scriptorium_, the _Bibliothèque Virtuelle des Manuscrits Médiévaux_ or _Manus Online_. These images appear more and more often in our classrooms when we teach, on our laptops when we do research, and during conference presentations here at Kalamazoo.

- However, EEBO offers more than a simple catalogue of images. Thanks to the Text Creation Partnership, launched in the early 2000s and based in the library of the University of Michigan, about one third of the books stored on this database can also be searched and manipulated as text. In other words, a large number of the facsimiles that can be accessed through EEBO exists both as a set of photographs and as a complete digital transcription. The two are mapped onto each other. Therefore, when I search the word "cat" in the database, the database allows me to examine not only the verbal context in which the word appears, but also the layout of the page and the presence of images or annotations. So, because of these transcriptions, these early modern books can be searched in their entirety; and they lend themselves to complex and broad-ranging computational analyses concerning their contents and their language. In short, medievalists feel great envy for EEBO.

- Now, in spite of the high number of photographic reproductions available online, a Textual Creation Partnership for a medieval EEBO would probably demand far more work than the one involved in the transcription of these Early Modern books. The wide diversity of scripts and scribal hands, the countless dialectal and orthographical variants, and the ubiquitous presence of inconsistent abbreviations make the transcription of medieval _codices_ a great deal more expensive and time-consuming than the one of printed documents. For this reason, one might argue that training OCR models to transcribe these texts automatically would perhaps facilitate the process.

- Well, would it truly help? On the website of the Textual Creation Partnership we read that

> Because of the irregularity and difficulty of early printing, as well as the variable quality of the microfilm-based images from which we are working, optical character recognition cannot reliably “read” the EEBO images to produce an accurate electronic text. The review and correction of the text produced would be so expensive and labor-intensive that it is more efficient to simply key the work from scratch.

On a different page, the authors explain that "For books printed before 1700, and for images that are blurry, spotty, or have other quality issues, [_OCR_] fails almost entirely." So, how can we expect it to work adequately for _codices_ that were handwritten before the year 1500, and on pages that are often ripped or stained, or heavily annotated and decorated?

- Despite these odds, we felt that the question warranted an experiment, and for at least two reasons. First, because the technology behind OCR has kept improving. With the rise of machine learning, and with the increased availability of faster computers, scholars have managed to train models that can, for instance, estimate the date of a pre-modern manuscript--as researchers Wahlberg, Wilkinson and Brun have shown in 2016--or distinguish between various Latin scripts--as medievalists Kestemont, Christlein, and Stutzmann have described in 2017. Second, because similar experiments have been attempted in languages other than Middle English, often with promising results. Among these we can mention the _Monk_ system, developed at the University of Groningen under the supervision of Lambert Schomaker, and concentrating primarily on the transcription of manuscripts from the Low Countries; the _HIMANIS_ project, born out of a collaboration between the Centre National de la Recherche Scientifique and A2iA with the intention of cataloguing the French and Latin "Chancery Corpus"; and the wide-ranging _Transkribus_ platform, launched by Tobias Hodel at the University of Innsbruck, and deployed--among other purposes--for German and Latin Gothic scripts.

- Inspired by these results, we decided to try Optical Character Recognition on a small corpus of Middle English _codices_. How rapidly and effectively could our team of two medievalists teach a computer to read a 15th-century Middle English book hand? And, moreover, what challenges would it encounter in the process?

- To begin with, we needed to find a suitable OCR system to use. In the fall of 2017 we contacted some of the scholars behind OpenITI, the Open Islamicate Texts Initiative. This international group of researchers had just performed Optical Character Recognition on a corpus of classical Arabic-script books in print, with an accuracy that fluctuated between 70 and 90 percent. Those of them with whom we talked and remained in touch over email--Sarah Savant at the University of London, Matthew Miller at the University of Maryland, and Benjamin Kiessling at the Universität Leipzig--shared their methods and findings with remarkable generosity.

- Of course, you might be wondering why we decided to turn to a system that had been used not only for a different period, but also for a different medium, a different language, and an entirely different alphabet. Well, we did so for three reasons.

- First, because the turn-key OCR suite developed and maintained by Benjamin Kiessling, _Kraken_, is distributed as open software. Therefore, any scholar can not only use it freely, but also figure out how it works, and--depending on one's technological prowess--alter it according to one's specific needs.

- Second, because _Kraken_ is designed for connected scripts, like Arabic. In other words, the system learns to recognize writing not letter by letter, but line by line. As a consequence, we assumed that it would perform well on 14th and 15th-century book hands, often characterized by biting, ligatures, and thick sequences of minims.

- Third, because _Kraken_ relies on an advanced form of machine learning known as a "neural network." This roughly means that it instructs the computer to behave like a human brain. So, rather than providing the machine with a set of rules on how to turn an image into a text, the scholar feeds it two things: a set of images and their complete transcription. Using these, the machine itself "learns" how to transcribe, determining these rules on its own. This process is called "training," and the resulting set of rules is called a "model."

- So, we chose to train an OCR model using _Kraken_. But on what manuscript? Our choice fell on _Corpus Christi 198_, an incomplete copy of the _Canterbury Tales_ held at Oxford, and dating from the early 15th century. Its tidy book hand, an almost quintessential version of the script known as "anglicana formata," has been attributed to one of the scribes behind the Trinity _Confessio Amantis_. Doyle and Parkes call him Scribe D, and Mooney and Stubbs have identified him with John Marchaunt, a Guildhall Clerk. Arguably, they propose, he belonged to a tight scribal network that hinged on this London institution. The considerable number of manuscripts ascribed to him and to his circle, together with the ostensible representativeness of his hand for late medieval Middle English, made of _Corpus Christi 198_ a fitting case study. Moreover, the manuscript featured relatively little decoration and virtually no damage, and had been digitized as a high-quality facsimile on the easily accessible--and now defunct--website of the _Early Manuscripts at Oxford University_ project.

- Having identified a system and a manuscript, we proceeded with the training of our model. On our end, this process mostly consisted in preparing the transcriptions which would be fed to _Kraken_ alongside the corresponding images, so that the machine could learn how to read. We manually transcribed about 1,330 lines from _Corpus Christi 198_, amounting to 40 pages. Later we also transcribed 42 more pages for testing purposes; these were drawn both from this manuscript and from a small set of contemporary ones. To guide our work we relied on the Chaucer Society text of _Corpus Christi 198_, edited by Frederick Furnivall in 1869.

- We fed _Kraken_ the images and our plain text transcriptions. Then, we ran the training program and waited, occasionally checking the results that appeared on screen over the course of six hours. We could witness the machine making attempts and correcting itself, from the strings of "Es" of the first trial to the somewhat recognizable words that appeared more and more often after the sixth.

- We stopped the program around its 36th cycle, and then tested the resulting model on _Corpus Christi 198_ itself and on four more contemporary manuscripts. On _Corpus Christi 198_, the OCR performed decently; its accuracy rate fluctuated between 90 and 85 percent. On _Harley 7334_, a different copy of _Canterbury Tales_ attributed to scribe D, it went down to about 80 percent. Then, on Scribe D's sections of the Trinity _Confessio Amantis_, it dropped to 70 percent. On _Trinity_ B.15.17, a copy of _Piers Plowman_ attributed to another scribe in his circle, it fell below 60 percent. Finally, it recognized less than 20 percent of the letter forms contained in Corpus Christi 201, a _Piers Plowman_ which features a far more cursive form of Anglicana. The decrease in these numbers should not come across as surprising. Of course, the more we depart from the single scribe, text, and script on which the model was trained, the less reliably this performs. Accordingly, future experiments could concentrate on training models that encompass multiple hands and variants.

- In conclusion, _Kraken_ seems to achieve far more than the "almost entir[e]" failure envisioned, for instance, by the Textual Creation Partnership. In fact, as OCR becomes increasingly effective, more medievalists should be involved in the discussions surrounding its implementation. For instance, how can we devise a consistent UNICODE standard for abbreviations and diplomatic transcriptions, as demanded by these systems? Or, should we rely on dictionaries to facilitate word recognition, at the cost of overlooking scribal errors? The investigation goes on.
