---
title: "Conference Paper: Leeds 2019"
author: J. Schoen & G. E. Saretto
date: May 2019
---
- In this talk we will tell you about an experiment with Optical Character Recognition that we started about a year and a half ago. We have been working within Columbia's Group for Experimental Methods in Humanistic Research, and we were also funded by Columbia's Data Science Institute during the summer of 2018. The experiment itself consisted in using a preexistent OCR software--called _Kraken_, like Tennyson's giant squid--to train a model for the automatic recognition and transcription of a Middle English book hand from the early 15th century. We will first discuss the potential implications of OCR technology, briefly overview how OCR works, and outline our particular experiment. We will then turn to the particular challenges that we faced during our experiments. Over the past year, several other research teams have received similar results to our own using OCR on medieval scripts. And so we think this is an important point in the research stage to reflect on certain decisions any researcher working with this technology must make. Ultimately, we hope to encourage a larger conversation about these choices among a range of medievalists.

- First, we'd like to discuss why we were interested in automatic transcription in the first place. As we know, human transcription is expensive and enormously time-consuming: it requires a trained paleographer and hours of labor per manuscript. If machines could produce transcriptions quickly and en-masse, not only would researchers save time and money, but the field would be flooded with new digital texts. With more transcriptions, we could compare more manuscripts across a single textual tradition or discover more about lesser-known texts. Transcriptions could be checked and edited for formal digital and print editions, but even a database of purely automatic transcriptions would be useful for many scholars, who could read and search across texts for relevant information and then double check digital facsimiles when necessary. Depending on accuracy, researchers could search precisely within digital facsimiles and read full transcriptions alongside the virtual pages. Digital transcriptions could be used as datasets for large-scale data analysis, such as topic modeling and text mining. Finally, machines might eventually prove to be more accurate transcribers than humans, or at the very least they might be less prone to making the kinds of transcription errors that humans make. For example, when a scribe makes an error in his own copy, a human transcriber might unconsciously correct that error in her transcription; if a machine is trained to recognize letter forms alone, and does not have any language training, it would not make the same kind of false correction.

- Optical Character Recognition (OCR) is a promising technology for automatic transcription. OCR transforms a text-image—for example a scanned book or a photograph of a document—into machine-readable text. That text can then be digitally searched, edited, stored, and otherwise manipulated by a computer. OCR technology already underlies many of the digital texts we read: it is what enables Project Gutenberg to easily digitize printed texts and Google Books to perform keyword-searches on scanned books. OCR models are built through machine learning, meaning that the machine executes tasks through inferred rules rather than explicit instruction. The machine learns these inferred rules through a "training" process, wherein a researcher provides the machine with a "training set" of paired inputs and outputs. The machine then instructs itself on this training set: it generates a model which, given a random input, guesses an output, it compares the guess to the target output, it adjusts the model accordingly, and it repeats this process until the model guesses outputs as accurately as possible without "overfitting". To use manuscript transcription as an example, a machine is first given a training set composed of manuscript images (input) alongside corresponding human-made transcriptions (output); the machine next “trains” on the images and transcriptions and “learns” the transcription rules on its own through guessing and correcting. The machine can then produce its own transcriptions on new, previously unseen images.

- We decided to try OCR on a small corpus of Middle English manuscripts. To begin with, we needed to find a suitable OCR system to use. We decided on Kraken, which is a turn-key OCR suite developed and maintained by Benjamin Kiessling. Kraken has two primary benefits: first, it is open software, and so any scholar can not only use it freely, but also figure out how it works, and--depending on one's technological prowess--alter it according to one's specific needs. Second, _Kraken_ is designed for connected scripts, like Arabic, which means that it learns to recognize writing not letter by letter, but line by line. As a consequence, we assumed that it would perform well on 14th and 15th-century book hands, often characterized by biting, ligatures, and thick sequences of minims.

- After selecting our OCR system, we next needed to selected our training manuscript--which is, again, the manuscript we would teach the machine to transcribe. We selected Oxford _Corpus Christi 198_, which is a Canterbury Tales manuscript that was copied between between 1410 and 1420 by "Scribe D." Scribe D was one of the most prolific scribes of the late 14th century and early 15th century in England, and his handwriting is also considered to be one of the highest quality hands of the period. He writes in very neat Anglicana Formata, a script that draws letter forms from both formal and cursive scripts, such as Gothic, documentary, and Secretary; thus, Anglicana Formata poses similar challenges to automatic transcription as other medieval hands; for example, it features both the loops and slants of documentary and the minim compression of Gothic. Scribe D has the added benefit of working in the same professional circle as several other prominent London scribes (most famously as one of five scribal hands found in the Trinity Confessio Amantis (MS R.3.2). Thus, a model based on Scribe D could be tested specifically on the scribes within his professional circle to assess the applicability of a single-scribe model to similar scribes. Finally, and perhaps most importantly, we were able to download high-resolution images of MS 198 via the Early Manuscripts at Oxford University project. We will return this point in a bit.

- Having chosen a suitable manuscript and page range for our training set, we then proceeded to produce our own transcriptions of the manuscript images. Our training data amounted to about 1,330 lines, distributed across 40 manuscript pages. We fed _Kraken_ the images and our plain text transcriptions. Then, we ran the training program and waited, occasionally checking the results that appeared on screen over the course of six hours. We could witness the machine making attempts and correcting itself, from the strings of "Es" of the first trial to the somewhat recognizable words that appeared more and more often after the sixth. We stopped the program around its 36th cycle, and then tested the resulting model on _Corpus Christi 198_ itself and on four more contemporary manuscripts. On _Corpus Christi 198_, the OCR performed decently; its accuracy rate fluctuated between 90 and 85 percent. On _Harley 7334_, a different copy of _Canterbury Tales_ attributed to scribe D, it went down to about 80 percent. Then, on Scribe D's sections of the Trinity _Confessio Amantis_, it dropped to 70 percent. On _Trinity_ B.15.17, a copy of _Piers Plowman_ attributed to another scribe in his circle, it fell below 60 percent. Finally, it recognized less than 20 percent of the letter forms contained in Corpus Christi 201, a _Piers Plowman_ which features a far more cursive form of Anglicana. The decrease in these numbers should not come across as surprising. Of course, the more we depart from the single scribe, text, and script on which the model was trained, the less reliably this performs. Accordingly, future experiments could concentrate on training models that encompass multiple hands and variants.

- Since we began this project, we have come across several other research teams which have achieved similar results to our own. Most notably: _Himanis_, _Transkribus_ and Hawk et al. It is encouraging to see such promising results across different medieval scripts and languages. Since various research teams would like to spend the rest of the talk discussing certain challenges to OCR which we faced during our own experiment, and which we have not seen fully addressed yet in articles and blog posts from researchers working similarly on OCR and medieval manuscripts.

- First, we would like to discuss the decisions behind manual transcriptions which are used to train the machine. Not only did the preparation of these manual transcriptions ultimately constitute the bulk of our work, but it also posed the largest number of challenges. This is because Kraken—like most contemporary OCR systems—requires “diplomatic transcriptions,” in other words a transcription where every letter form represented on the page corresponds to a single character—or glyph—of plain text, in a strict one-to-one correlation. In paleography, the term “diplomatic transcription” similarly refers to transcriptions which render the text of a manuscript into representative glyphs. But in practice, most transcriptions are actually “semi-diplomatic”—for example, expanding abbreviations in italics or parentheses (in fact most medieval transcription guidelines specifically call for abbreviations to be expanded). Therefore, even though a print transcription of our training manuscript does exist, since it expands abbreviations like most transcriptions do, we could not simply copy this text. Because we needed to render abbreviations into single Unicode characters, we had to assemble our 1,330 lines of training data from scratch, together with some 1,400 additional lines which we transcribed for testing purposes.

- Presumably because semi-diplomatic transcriptions are the paleographic standard, there is no convention for rendering medieval abbreviations into Unicode characters. In other words, since print and digital transcriptions by and large expand abbreviations, there has been no need to create standards for digitally rendering abbreviations. We therefore had to create our own guideline for digital abbreviations, which required categorizing them and assigning them systematized Unicode characters (for example, rendering the “er” loop abbreviation with the ◌̉ diacritic, as in d̉). We decided to limit our selection of characters according to those proposed in the guidelines of the Medieval Unicode Font Initiative (MUFI). In particular, we followed MUFI’s recommendations to render less common characters and abbreviations through dependable Unicode encodings, thus ensuring that these could be displayed adequately across different systems and applications. Categorizing the abbreviations was a separate undertaking, given that there is no standard handbook for Middle English abbreviations (such as Cappelli serves for Latin paleography).

- There are also certain discrepancies among transcription systems which deserve particular attention as OCR technology improves. For example, paleographers have developed different systems for marking features such as erasures, corrections, and interlinear insertions. While these particular marks were not necessary for any of our transcriptions, they will certainly be necessary in future training sets. Moreover, a precise and consistent set of guidelines concerning how to prepare a transcription does not seem to exist yet, and these guidelines will be  required as we continue to train machines. If we are to successfully teach a machine to transcribe a manuscript, we need to agree on what a successful transcription looks like.

- Future software may be able to expand abbreviations in post-processing, and OCR technology may even be able to render semi-diplomatic transcriptions down the line. But the successful training of these models will still rest on the establishment of a shared and sustainable standard for transcriptions. Perhaps we will not only develop different models for different scripts, but also different models for different levels of transcription. Regardless, the imminent rise of OCR will compel scholars to reflect again on what features of a medieval script should be deemed essential to remediate and why.

- Second, we would like to discuss the importance of open technology and data across medieval studies. Most importantly, it’s essential that all researchers working on automatic transcription projects make their training data and models freely available online. This way researchers can experiment with new OCR systems, collectively generate a large corpus of training manuscripts, and use trained OCR models for various transcription projects.

- Relatedly, training a transcription machine requires digital images of manuscripts. Luckily thousands of medieval manuscripts are fully digitized, and future digitization projects will provide more candidates for training and transcriptions. However, even though many manuscripts are digitized and available to view online in high-resolution, most libraries do not allow these images to be downloaded in high-resolution, which is required for the training process. Even in our relatively small experiment, we were extremely limited by the manuscript images freely available to download and those which libraries agreed to send us. While institutions may not want to make these images publically available, they will need to share them with researchers if they want a tool which will significantly improve their digital editions in the long run.

- [Maybe say something about open-software in general? Something about how doing projects like this can open our eyes to how restrictive the field can be?]

- In conclusion, we want to reiterate both the the promising results of our experiment as well as the intriguing challenges ahead. We are excited by this technology's potential, and our experiment proved more successful than we imagined: but after working through this process, we have also come to realize that there critical conversations to be had about the [kinds of transcription we want this technology to produce, what a transcription is in the first place, and what kinds of biases underlie any transcription of a manuscript-- both in today's digital age and in the history of medieval studies]
