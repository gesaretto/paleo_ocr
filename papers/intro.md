In the 1340s a scribe in Ludlow compiled a curious collection of Middle English, Anglo-Norman, and Latin texts, with both prose and verse works that range from somber religious allegory to bawdy fabliau. The scribe then attached his miscellaneous folios to two older booklets of Anglo-Norman religious writing (a previous scribe's work) and formed the manuscript now known as Harley 2253. Harley 2253 is a decidedly multilingual manuscript--Middle English, Latin, and Anglo-Norman texts alternate regularly, several pages contain two or three languages side-by-side, and there are even some bilingual and trilingual poems in the collection. The polyglot manuscript is fertile ground for comparative literary analysis, whether scholars are interested in historicizing a multilingual 14th century England, exploring genres and themes across multiple languages, or tracking linguistic interplay and influence. But in the 20th century, the English, French, and Latin texts were never edited alongside each other. Instead, the Middle English texts were edited separately, and the Latin and Anglo-Norman texts were largely ignored. Even a facsimile of the manuscript omitted the first two booklets (containing the Anglo-Norman texts copied by a different scribe). The Middle English lyrics were given special attention, and although the manuscript actually features more Anglo-Norman poems, "Harley Lyrics" became shorthand for the Middle English lyrics alone. Scholarly analysis reinforced the decisions of scholarly editions and vice-versa: as the "Harley Lyrics" became a cornerstone of the Middle English canon, the manuscript itself was considered primarily significant for its unique and extensive collection of secular Middle English lyrics. Thus a distinctly multilingual manuscript was for decades edited and studied almost exclusively for its monolingual holdings, while little attention was given to its larger structural, thematic, and cross-linguistic meaning.


\[fix transition: Significant work has been done in the past twenty years to correct this scholarly bias, including a momentous edition of the entire manuscript and a collection of essays which considers "the manuscript as a whole" (cite). But Harley 2253 is not the primary concern of this paper. Rather, this paper examines a new method for conveying information about manuscripts--automatic transcription. What is interesting about Harley 2253 for our purposes is that such a bias guided its editorial history for so long.\]

\[fix transition: If we consider the editorial history of Harley 2253 from a digital mindset, we can see that it is a clear case of data manipulation.\] In plucking the Middle English lyrics out of their original context and presenting them as a homogenous set, scholars mined the manuscript for select information and discarded the rest. They manipulated the manuscript's data according to a certain bias--in favor of Middle English and prejudiced against Latin and Anglo-Norman. Even the facsimile edition--typically the most transparent edition imaginable--distorted data by leaving out the first two quires, reflecting a bias in favor of single scribes. Of course, this is what editions *are*--selections, curations, manipulations. Though Harley 2253's history may be exemplary, any medieval manuscript's editorial history is a history of data manipulation. \[what's transition then?\]

As editors transfer a manuscript to a new medium, some data will always be lost. New mediums provide certain rewards (e.g. legibility, access, convenience) at the cost of certain information (e.g. page layout, material, handwriting, context). This is not to say that certain kinds of mediums and editions are objectively superior to others: collecting the Middle English Harley lyrics together allowed scholars to focus on an understudied area of scholarship. Rather it is to say that we simply need to be aware of the implicit and explicit decisions behind any kind of remediation.

\[transition\] The digital era has ushered in a whole new set of mediums for representing manuscripts--digital facsimiles, digital editions, isolated images of manuscript pages and illustrations. As with print, these new mediums raise questions about how to best represent manuscripts across different contexts and for different purposes. But the digital era is also introducing new forms of remediation--that is, changing not only the medium through which we reproduce manuscripts, but the *process* by which we do so. Editors can rely on digital images rather than a physical manuscript; the internet allows scholars to more easily collaborate on editions; some research teams are even crowdsourcing transcriptions. And the next form of remediation is the machine itself.

Thanks to advancements in Optical Character Recognition (OCR), several research teams (including our own) are successfully beginning to train machines to transcribe medieval scripts. In this paper, we discuss our method for training an OCR system as well as our promising results. But we also discuss important considerations for any team embarking on an automatic transcription project. As we move towards machine-made transcriptions, questions about data manipulation and bias are perhaps more important than ever.

While the potential benefits of automatic transcription are manifold--quick and large-scale transcriptions of understudied manuscripts, keyword searches on digital facsimiles, less human error--the process comes with new constraints. These constraints are not necessarily better or worse than the constraints of any other medium--they are simply different. What is essential, however, is that we carefully consider them.

However these constraints us to make new transcription decisions and to rethink transcription decisions that have been made throughout the history of manuscript studies.

Like any other time in a manuscript's editorial history, the present moment offers a specific set of constraints and possibilities. **We can see OCR as a moment in book history, just as we can read book history through the lens of data science.**
ocr as a moment in book history -- one which constrains us in a certain way and opens us up in a different way, one which offers certain questions (is it better automate transcriptions? how much of the manuscript should we render on the screen? is there a benefit to digital renderings of abbreviations -- i.e. fully diplomatic transcriptions?)
book history through data science -- as always biased and manipulative

Machine learning requires researchers to be precise and thoughtful about their training data: when the training data is manuscript transcriptions, medievalists have to consider transcription decisions carefully. Especially as more medievalists begin to experiment with OCR, it is crucial that we consider our transcription decisions. But even outside machine learning, and simply within medieval studies, this experiment raises important considerations and forces us to reconsider the biases and decisions that undergird manuscript studies in the first place.

(footnote?) In the past twenty years, work has been done to reconsider Harley 2253 in its entirety, including a monumental TEAMS edition of the entire manuscript (with modern English translations of the French and Latin texts) and an essay collection "the manuscript as a whole" (Fein *Studies in the Harley Manuscript* 10). But for a significant time in medieval studies, scholars were primarily concerned with the "Harley Lyrics" rather than Harley 2253 itself.
